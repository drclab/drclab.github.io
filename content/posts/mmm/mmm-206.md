+++
title = "MMM 206: A Crosswalk from Data to Methods"
date = 2026-02-13
type = "post"
draft = false
categories = ["posts", "stats"]
tags = ["marketing", "causal-inference", "mmm", "panel-data"]
description = "A practical map from data structures and estimands to the right causal estimators and diagnostics in marketing panels."
math = true
+++

## Why a crosswalk helps
After defining estimands (Section 2.3) and assignment mechanisms (Section 2.4), the next step is choosing methods that match those choices. Section 2.6 provides a crosswalk: it links data structure and identification assumptions to the most appropriate estimators and diagnostics. The main message is simple: estimator choice is not arbitrary, it follows from design.

## Core idea: match estimand, design, and estimator
A good analysis lines up three pieces:
- **Estimand:** What causal quantity are you targeting (ATE, ATT, $\tau(g,t)$, $\theta_k$)?
- **Assignment mechanism:** How did treatment happen (randomized, staggered, single treated unit, exposure)?
- **Identification assumption:** What makes the counterfactual believable (parallel trends, factor structure, unconfoundedness, interference model)?

If any piece is mismatched, you can get a precise estimate of the wrong quantity.

## Staggered adoption with binary treatment
When treatment rolls out over time, the natural target is cohort-time effects $\tau(g,t)$ or their aggregations. The crosswalk points to **modern DiD** and **event studies**, not naive TWFE.

Key requirements:
- Parallel trends across cohorts pre-treatment.
- No anticipation for dynamic interpretation.

Diagnostics:
- Pre-trend checks ($k<0$ event-time coefficients).
- Sensitivity analysis for deviations from parallel trends.

## Single treated unit and synthetic control
With one or a few treated units, variation in timing is minimal. The recommended tools are **synthetic control** and **synthetic DiD (SDID)**.

Key requirement:
- Good pre-treatment fit under a stable low-rank factor structure.

Diagnostics:
- Placebo tests across control units.
- Pre-treatment fit quality and leave-one-out checks.

## Common shocks with heterogeneous exposure
When all units are exposed to the same shock but at different intensity (e.g., national campaigns with different local GRPs), you can no longer treat time effects as uniform. The crosswalk recommends **interactive fixed effects** or **matrix completion**.

Key requirement:
- A low-rank factor structure that captures common shocks with unit-specific loadings.

Diagnostics:
- Sensitivity to factor rank choices.
- Predictive fit of untreated periods.

## Continuous treatment intensity
Marketing treatments are often continuous: spend, discount depth, or exposure. The crosswalk points to **dose-response methods**, **double machine learning (DML)**, and **high-dimensional controls**.

Key requirement:
- Conditional unconfoundedness for treatment intensity.

Diagnostics:
- Covariate balance across intensity bins.
- Robustness to alternative nuisance models.

## Spillovers and interference
When SUTVA fails, estimands change. Instead of $Y_{it}(d)$, outcomes depend on others' treatment through an exposure mapping $h_i(D_{-i,t})$.

Recommended tools:
- Interference-aware designs and spillover models.
- Spatial or network econometric approaches.

Key requirement:
- A defensible exposure mapping and network structure.

## Dynamic effects and carryover
If treatment effects unfold over time, static models mislead. The crosswalk recommends **distributed lag models** and **event studies** to estimate the dynamic profile $\{\theta_k\}$.

Key requirements:
- No anticipation for lead coefficients.
- A plausible lag specification.

Diagnostics:
- Stability of dynamic responses across windows.
- Pre-treatment lead coefficients near zero.

## Where machine learning fits
Machine learning does not replace identification. It improves estimation of nuisance components inside the chosen design:
- DML for flexible outcome and treatment models.
- Causal forests for heterogeneous effects.
- High-dimensional variable selection for rich confounding control.

The identification assumptions remain the same; ML relaxes functional-form assumptions, not causal ones.

## Table 2.2, distilled
| Data structure | Primary methods | Key requirement |
| --- | --- | --- |
| Randomized experiment | Geo / A-B experiments | Design-based unconfoundedness; limited interference |
| Staggered adoption | DiD, event studies | Parallel trends; no anticipation |
| Single treated unit | Synthetic control, SDID | Good pre-treatment fit under factor structure |
| Common shocks, heterogeneous exposure | IFE, matrix completion | Low-rank factor structure |
| Continuous treatment | DML, high-dim controls | Conditional unconfoundedness |
| Spillovers | Spillover models | Network or geo exposure mapping |
| Dynamic effects | Distributed lags, event studies | Lag specification; no anticipation |

## Takeaway
The crosswalk is a guardrail: it forces you to state the causal target and then choose estimators that are logically compatible with the data and assumptions. When the mapping is clear, diagnostics become purposeful and inference becomes more credible.

## References
- Shaw, C. (2025). *Causal Inference in Marketing: Panel Data and Machine Learning Methods* (Community Review Edition), Section 2.6.
- Callaway, B., and Sant'Anna, P. H. C. (2021). Difference-in-differences with multiple time periods. *Journal of Econometrics*.
- Sun, L., and Abraham, S. (2021). Estimating dynamic treatment effects in event studies. *Journal of Econometrics*.
- Abadie, A., Diamond, A., and Hainmueller, J. (2010). Synthetic control methods for comparative case studies. *Journal of the American Statistical Association*.
