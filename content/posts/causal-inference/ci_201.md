+++
title = "CI 201: Causal Inference with PyMC"
date = "2025-11-30"
type = "post"
draft = false
math = true
tags = ["pymc", "causal inference", "bayesian", "python"]
categories = ["causal-inference"]
description = "Introduction to causal inference using Probabilistic Programming Languages (PPLs) with PyMC, featuring the classic Lalonde dataset."
+++

Causal inference asks a deceptively simple question: "What would have happened if things were different?" Whether we're evaluating a job training program, testing a new medical treatment, or analyzing the impact of a policy change, we want to understand the causal effect of an intervention not just observe correlations in the data.

Traditional statistical methods often struggle with causal questions because they conflate correlation with causation. When confounders—variables that affect both treatment assignment and outcomes—are present, naive comparisons can lead us astray. This post demonstrates how probabilistic programming languages (PPLs) provide a powerful framework for causal inference that makes confounding explicit, quantifies uncertainty properly, and enables us to answer counterfactual questions directly.

## Why Probabilistic Programming Languages?

Probabilistic Programming Languages (PPLs) like NumPyro, PyMC, and Stan offer several compelling advantages for causal inference:

1. **Express causal models naturally**: We can explicitly model both the treatment assignment mechanism and the outcome process, making confounding relationships transparent in our code. This aligns perfectly with Pearl's structural causal models and the backdoor criterion.

2. **Quantify uncertainty rigorously**: Bayesian inference gives us full posterior distributions, not just point estimates. We get credible intervals that properly account for all sources of uncertainty, from parameter estimation to model specification.

3. **Implement the `do` operator directly**: PPLs let us implement Pearl's do-calculus naturally, allowing us to compute counterfactuals ("what if everyone received treatment?") by simply conditioning on interventions rather than observations.

4. **Flexible modeling without sacrificing interpretability**: We can use non-linear models, hierarchical structures, and other sophisticated approaches while maintaining clear causal interpretability. The same framework works for simple linear models and complex hierarchical designs.

## The Lalonde Dataset

We'll work with the famous [Lalonde dataset](https://rugg2.github.io/Lalonde%20dataset%20-%20Causal%20Inference.html) which studies the effect of a job training program on earnings. This dataset is a classic in causal inference because it vividly demonstrates how naive comparisons can be misleading when confounders are present. The treated and control groups differ systematically in pre-treatment characteristics (age, education, prior earnings, etc.), making a simple comparison of means unreliable. By properly adjusting for these confounders, we can uncover the true causal effect of the training program.

**Reference**: Robert Lalonde, "Evaluating the Econometric Evaluations of Training Programs", American Economic Review, Vol. 76, pp. 604-620

### Data Loading and Preprocessing

```python
import arviz as az
import graphviz as gr
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pymc as pm
import pytensor.tensor as pt
import seaborn as sns

data_path = "https://raw.githubusercontent.com/rugg2/rugg2.github.io/master/lalonde.csv"
data = pd.read_csv(data_path)

# Convert the data to the right format
data["re75"] = data["re75"] / 1_000
# Add a small constant to avoid log(0) in the model
data["re78"] = data["re78"] / 1_000 + 1e-6
data = data.rename(columns={"educ": "education", "hispan": "hispanic"})

# Define the covariates
covariates_names = [
    "education",
    "age",
    "re75",
    "black",
    "hispanic",
    "married",
    "nodegree",
]

# Extract treatment, covariates and earnings from the dataframe
df = data[["treat", *covariates_names, "re78"]]
n_obs = df.shape[0]
df.head()
```
   treat  education  age  re75  black  hispanic  married  nodegree       re78
0      1         11   37   0.0      1         0        1         1   9.930047
1      1          9   22   0.0      0         1        0         1   3.595895
2      1         12   30   0.0      1         0        0         0  24.909451
3      1         11   27   0.0      1         0        0         1   7.506147
4      1          8   33   0.0      1         0        0         1   0.289791
```
```

## Causal DAG

Before building our models, we need to establish a clear understanding of the causal relationships in the data. We have the following structure:

- **Treatment variable** (`treat`): The intervention we're studying (job training program)
- **Outcome variable** (`re78`): What we want to measure the effect on (earnings in 1978)
- **Covariates**: Pre-treatment variables that might confound the relationship

```python
dag = gr.Digraph()
dag.node("treat", color="#2a2eec80", style="filled")
dag.node("re78", color="#fa7c1780", style="filled")
dag.edge("treat", "re78")
for covariate in covariates_names:
    dag.edge(covariate, "treat")
    dag.edge(covariate, "re78")
dag
```

![Causal DAG](/images/causal-inference/ci_201/dag_detailed.svg)
```

## PyMC Model

We can model the causal structure directly in PyMC. We'll define two components:
1.  **Treatment Model**: Models the probability of receiving treatment based on covariates.
2.  **Earnings Model**: Models the outcome (earnings) based on treatment and covariates.

```python
# Prepare data for PyMC
covariates_obs = df[covariates_names].values
treat_obs = df["treat"].values
earnings_obs = df["re78"].values

coords = {
    "covariate": covariates_names,
    "obs_idx": df.index,
}

with pm.Model(coords=coords) as earnings_model:
    # TREATMENT MODEL
    # --- Data Containers ---
    covariates_data = pm.Data(
        "covariates_data",
        covariates_obs,
        dims=("obs_idx", "covariate")
    )
    
    # --- Priors ---
    intercept_treat = pm.Normal("intercept_treat", mu=0, sigma=10)
    beta_covariate_treat = pm.Normal(
        "beta_covariate_treat",
        mu=0,
        sigma=1,
        dims=("covariate",)
    )
    
    # --- Parametrization ---
    logit_p_treat = intercept_treat + pm.math.dot(covariates_data, beta_covariate_treat)
    p_treat = pm.math.sigmoid(logit_p_treat)
    
    # --- Likelihood ---
    treat = pm.Bernoulli("treat", p=p_treat, observed=treat_obs, dims=("obs_idx",))
    
    # EARNINGS MODEL
    # --- Priors ---
    intercept_earnings = pm.Normal("intercept_earnings", mu=0, sigma=10)
    beta_treat_earnings = pm.Normal("beta_treat_earnings", mu=0, sigma=10)
    beta_covariate_earnings = pm.Normal(
        "beta_covariate_earnings",
        mu=0,
        sigma=1,
        dims=("covariate",)
    )
    sigma_earnings = pm.HalfNormal("sigma_earnings", sigma=10)
    
    # --- Parametrization ---
    # Note: We use the observed treatment here for the likelihood
    mu_earnings = (
        intercept_earnings
        + beta_treat_earnings * treat
        + pm.math.dot(covariates_data, beta_covariate_earnings)
    )
    
    # --- Likelihood ---
    earnings = pm.Normal(
        "earnings",
        mu=mu_earnings,
        sigma=sigma_earnings,
        observed=earnings_obs,
        dims=("obs_idx",)
    )
```

### Sampling and Results

We can now sample from the posterior to estimate the parameters, including the Average Treatment Effect (ATE), which in this linear model corresponds to `beta_treat_earnings`.

```python
with earnings_model:
    idata = pm.sample(random_seed=seed)
    
az.summary(idata, var_names=["beta_treat_earnings", "intercept_earnings", "sigma_earnings"])
```
                                    mean     sd  hdi_3%  hdi_97%  mcse_mean  \
beta_covariate_earnings[education]  1.135  0.340   0.495    1.754      0.005   
beta_covariate_earnings[age]        0.508  0.297  -0.041    1.066      0.003   
beta_covariate_earnings[re75]       1.526  0.289   0.951    2.033      0.003   
beta_covariate_earnings[black]     -0.941  0.578  -2.063    0.105      0.006   
beta_covariate_earnings[hispanic]   0.238  0.693  -1.052    1.559      0.006   
beta_covariate_earnings[married]    0.778  0.561  -0.258    1.878      0.005   
beta_covariate_earnings[nodegree]  -0.149  0.631  -1.352    1.021      0.008   
beta_covariate_treat[education]     0.348  0.164   0.053    0.661      0.002   
beta_covariate_treat[age]           0.074  0.128  -0.162    0.317      0.001   
beta_covariate_treat[re75]         -0.048  0.120  -0.271    0.181      0.001   
beta_covariate_treat[black]         2.917  0.259   2.444    3.413      0.003   
beta_covariate_treat[hispanic]      0.709  0.384  -0.037    1.408      0.004   
beta_covariate_treat[married]      -0.871  0.273  -1.410   -0.377      0.003   
beta_covariate_treat[nodegree]      0.700  0.315   0.117    1.294      0.004   
intercept_treat                    -4.181  0.949  -5.967   -2.431      0.015   
beta_treat_earnings                 0.536  0.598  -0.632    1.638      0.006   
intercept_earnings                 -0.114  1.952  -3.579    3.603      0.029   
sigma_earnings                      7.098  0.208   6.708    7.485      0.002   

                                    mcse_sd  ess_bulk  ess_tail  r_hat  
beta_covariate_earnings[education]    0.003    5292.0    5566.0    1.0  
beta_covariate_earnings[age]          0.003    8192.0    6189.0    1.0  
beta_covariate_earnings[re75]         0.003   12355.0    6211.0    1.0  
beta_covariate_earnings[black]        0.006    9531.0    5952.0    1.0  
beta_covariate_earnings[hispanic]     0.008   11391.0    6044.0    1.0  
beta_covariate_earnings[married]      0.006   11149.0    6319.0    1.0  
beta_covariate_earnings[nodegree]     0.006    6045.0    6583.0    1.0  
beta_covariate_treat[education]       0.002    4712.0    5801.0    1.0  
beta_covariate_treat[age]             0.001    8007.0    5532.0    1.0  
beta_covariate_treat[re75]            0.001   10239.0    6484.0    1.0  
beta_covariate_treat[black]           0.003    8886.0    5756.0    1.0  
beta_covariate_treat[hispanic]        0.004    9490.0    6236.0    1.0  
beta_covariate_treat[married]         0.003    9376.0    6104.0    1.0  
beta_covariate_treat[nodegree]        0.003    5197.0    5850.0    1.0  
intercept_treat                       0.010    4081.0    5104.0    1.0  
beta_treat_earnings                   0.007   10444.0    6179.0    1.0  
intercept_earnings                    0.021    4474.0    5160.0    1.0  
sigma_earnings                        0.003   12503.0    5451.0    1.0  
```
```

The posterior distribution of `beta_treat_earnings` gives us the estimated causal effect of the job training program on earnings, adjusted for the observed covariates. If the 94% HDI excludes zero, we have strong evidence of a causal effect.

By using a PPL, we've made our assumptions explicit in the model structure. We can easily extend this to more complex scenarios, such as non-linear relationships or unobserved confounding (using instrumental variables), all within the same probabilistic framework.

## Posterior Predictive Checks

Posterior predictive checks (PPCs) are a vital step in the Bayesian workflow. They allow us to assess how well our model captures the data generating process by comparing the observed data to data generated from the model's posterior predictive distribution.

```python
with earnings_model:
    pm.sample_posterior_predictive(idata, extend_inferencedata=True, random_seed=rng)

fig, ax = plt.subplots()
az.plot_ppc(idata, var_names=["earnings"], num_pp_samples=200, ax=ax)
ax.axvline(earnings_obs.mean(), color="C2", label="observed earnings mean")
ax.axvline(
    idata["posterior_predictive"]["earnings"].mean().item(),
    color="C3",
    label="posterior predictive earnings mean",
)
ax.legend()
ax.set(xlabel="earnings", ylabel="Frequency")
ax.set_title(
    "Posterior Predictive Checks (earnings)",
    fontsize=18,
    fontweight="bold"
);
```

![Posterior Predictive Checks](/images/causal-inference/ci_201/ppc_plot.png)
```

The plot shows the distribution of observed earnings (black line) compared to the distributions of earnings generated by our model (blue lines). If the model is a good fit, the observed data should look like a plausible realization from the posterior predictive distribution.

## Conclusion

In this post, we've seen how PyMC allows us to build a causal model that explicitly represents our assumptions about the data generating process. By treating treatment assignment and the outcome as part of a joint probabilistic model, we can quantify our uncertainty about the causal effect of the job training program.

This approach offers a flexible and transparent alternative to traditional methods, especially when dealing with complex causal structures or when we want to incorporate prior knowledge.
