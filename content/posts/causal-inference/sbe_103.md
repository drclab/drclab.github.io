+++
title = "SBE 103: Regular Switchback Experiments"
date = "2026-11-23"
type = "post"
draft = false
math = true
summary = "Section 2.3 of Bojinov, Simchi-Levi, and Zhao (2023): how a regular switchback experiment is parameterized by a few coin flips, what counts as a valid design, and why fair coins end up optimal."
tags = ["causal-inference", "switchback-experiments"]
+++

Section 2.3 formalizes the design knob we actually control: the distribution over assignment paths. A **switchback design** is a discrete probability distribution defined as:

$$\eta: \{0,1\}^T \to [0,1] \text{ such that } \sum_{w_{1:T} \in \{0,1\}^T} \eta(w_{1:T}) = 1, \quad \eta(w_{1:T}) \geq 0, \quad \forall w_{1:T} \in \{0,1\}^T.$$

Explicitly, $\eta(\cdot)$ is the underlying discrete distribution of the random assignment path $W_{1:T}$. Drawing one assignment path $W_{1:T}$ means sampling from this law. A **regular switchback experiment** compresses that full distribution into a handful of randomization points and their coin biases.

## What "regular" means

- Pick time indices $\mathcal{T} = \{t_0=1 < t_1 < \dots < t_K\} \subseteq [T]$ as **randomization points**; set $t_{K+1} = T+1$ for convenience.
- Choose **coin biases** $\mathcal{Q} = (q_0, \dots, q_K)$ with each $q_k \in (0,1)$.
- At point $t_k$, flip a biased coin: heads assigns treatment for every period in $[t_k, t_{k+1}-1]$; tails assigns control for that block. Within a block, treatment status stays fixed.
- Together $(\mathcal{T}, \mathcal{Q})$ induce a discrete distribution $\eta_{\mathcal{T},\mathcal{Q}}$ over all assignment paths; its support contains exactly $2^{K+1}$ paths because each coin flip doubles the possibilities.

Formally, the induced distribution is given by:

$$\eta_{\mathcal{T},\mathcal{Q}}(w_{1:T}) = \begin{cases}
\prod_{k=0}^{K} \frac{\mathbb{1}\{w_{t_k} = 1\}}{q_{t_k}} \cdot \frac{\mathbb{1}\{w_{t_k} = 0\}}{\bar{q}_{t_k}}, & \text{if } \forall k \in \{0, 1, \ldots, K\}, \\
& \quad w_{t_k} = w_{t_k+1} = \cdots = w_{t_{k+1}-1}, \\
0, & \text{otherwise.}
\end{cases} \tag{3}$$

where $\bar{q}_{t_k} = 1 - q_{t_k}$. The formula says: a path gets positive probability only if it respects the block structure (treatment stays constant between randomization points), and that probability is the product of the individual coin-flip probabilities. Paths that switch treatment mid-block receive zero probability.

## Examples and non-examples

- **Example 3** (regular): $T=4$, $\mathcal{T}=\{1,3\}$, and $\mathcal{Q} = (1/2, 1/2)$ produce four equally likely paths: $(1,1,1,1)$, $(1,1,0,0)$, $(0,0,1,1)$, $(0,0,0,0)$. Notice that each coin flip at $t_0=1$ and $t_1=3$ creates a block, and within each block treatment status remains constant.

- **Example 4** (not regular): Consider a design where $T=4$ and you flip a fair coin at time 1, then **conditionally** flip another coin at time 3 only if the first coin was heads. This creates paths with unequal probabilities that cannot be represented by any fixed $(\mathcal{T}, \mathcal{Q})$ pair:
  - $(1,1,1,1)$ occurs with probability $1/2 \times 1/2 = 1/4$ (first flip heads, second flip heads)
  - $(1,1,0,0)$ occurs with probability $1/2 \times 1/2 = 1/4$ (first flip heads, second flip tails)
  - $(0,0,0,0)$ occurs with probability $1/2$ (first flip tails, no second flip)
  - Path $(0,0,1,1)$ has **zero probability** because if the first flip is tails, there is no second randomization

The problem: regular designs require **independent** coin flips at prespecified times $\mathcal{T}$. Example 4 violates this by making the second randomization conditional on the first outcome. You cannot write down a fixed set of randomization points and biases $(\mathcal{T}, \mathcal{Q})$ that produces this distribution, because the very existence of the second flip depends on runtime information.

More generally, any design that:
- Uses adaptive randomization (outcome-dependent or assignment-dependent flips)
- Allows treatment to change mid-block without a prespecified randomization point
- Creates dependencies between randomization points

falls outside the "regular switchback" family, even though it might still be a valid randomized design under the general framework.

## Why fair coins surface

- Under symmetry and minimal modeling assumptions, the authors show (Section 3) that **fair coins** $q_k = 1/2$ are optimal. Intuitively, no prior should tilt you toward treatment or control within any block.
- Adaptive schemes (updating $q_k$ mid-experiment) are excluded; the paper sticks to precommitted schedules, matching how most companies run switchbacks.

## Practical setup checklist

1. Decide how many flips you can afford (pick $K$) and place them to reflect plausible carryover length—blocks should be longer than lagged effects yet short enough to collect multiple flips.
2. Use $(\mathcal{T}, \mathcal{Q})$ to enumerate your support and confirm it contains the paths you actually want to test.
3. Default to $q_k = 1/2$ unless strong operational constraints force otherwise; doing so aligns with the paper’s optimality result.
4. Document $(\mathcal{T}, \mathcal{Q})$ as your design; inference later (Sections 3–4 of the paper) will condition on this distribution.
