{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Modeling a biased coin with BamoJAX\n\nThis notebook shows how to build a simple Beta\u2013Bernoulli model with `bamojax`, run Hamiltonian Monte Carlo via BlackJAX, and interpret both posterior and posterior predictive results.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Data\n\nWe'll treat the array below as 20 coin flips collected in the lab. A value of 1 represents heads, 0 represents tails.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import jax.numpy as jnp\nimport jax.random as jr\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport numpyro.distributions as dist\n\nfrom bamojax.base import Model\nfrom bamojax.samplers import mcmc_sampler\nfrom bamojax.inference import MCMCInference\n\nfrom blackjax import nuts\n\n%config InlineBackend.figure_format = 'retina'\nplt.style.use('seaborn-v0_8-darkgrid')\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "coin_flips = jnp.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0], dtype=jnp.int32)\nnum_trials = int(coin_flips.size)\nsuccesses = int(coin_flips.sum())\nfailures = num_trials - successes\n\nprint(f\"Observed {successes} heads and {failures} tails out of {num_trials} flips.\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Build the model\n\nBamoJAX represents Bayesian models as directed acyclic graphs of `Node` objects. We create a `Model`, place a uniform Beta prior on the coin bias `theta`, and attach a Bernoulli likelihood for each observed flip.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "model = Model(name=\"Beta-Bernoulli coin\")\n\ntheta = model.add_node(\"theta\", distribution=dist.Beta(1.0, 1.0))\nlikelihood = model.add_node(\n    \"y\",\n    distribution=dist.Bernoulli,\n    observations=coin_flips,\n    parents={\"probs\": theta},\n    shape=coin_flips.shape,\n)\n\nprint(\"Latent nodes:\", list(model.get_latent_nodes().keys()))\nprint(\"Leaf node:\", [node.name for node in model.get_leaf_nodes()])\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Configure and run NUTS\n\nBamoJAX wraps BlackJAX samplers. The first run triggers JAX compilation, so expect a small pause the first time you execute the cell.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "initial_kernel = mcmc_sampler(\n    model,\n    mcmc_kernel=nuts,\n    mcmc_parameters={\"step_size\": 0.1, \"inverse_mass_matrix\": jnp.array([1.0])},\n)\n\ninference = MCMCInference(\n    model=model,\n    num_chains=1,\n    mcmc_kernel=initial_kernel,\n    num_samples=2000,\n    num_burn=500,\n    num_warmup=500,\n    return_diagnostics=True,\n)\n\nrng_key = jr.PRNGKey(2)\n\nprint(\"Running NUTS sampling (first call may compile JAX kernels)...\")\nresults = inference.run(rng_key)\n\ntheta_samples = results[\"states\"][\"theta\"]\ndiagnostics = results[\"info\"]\n\nprint(f\"Collected {{theta_samples.shape[0]}} posterior samples.\")\nprint(f\"Average acceptance rate: {{float(diagnostics.acceptance_rate.mean()):.3f}}\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Posterior summary\n\nUse the samples to compute credible intervals, tail probabilities, and a quick conjugate-Beta check for intuition.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "theta_np = np.asarray(theta_samples)\nposterior_mean = theta_np.mean()\nposterior_ci = np.quantile(theta_np, [0.025, 0.5, 0.975])\nprob_theta_gt_half = (theta_np > 0.5).mean()\n\nposterior_alpha = 1.0 + successes\nposterior_beta = 1.0 + failures\n\nprint(f\"Posterior mean: {posterior_mean:.3f}\")\nprint(f\"Central 95% interval: [{posterior_ci[0]:.3f}, {posterior_ci[2]:.3f}]\")\nprint(f\"P(theta > 0.5 | data) = {prob_theta_gt_half:.3f}\")\nprint(f\"Conjugate Beta parameters (reference): alpha={posterior_alpha:.1f}, beta={posterior_beta:.1f}\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "fig, ax = plt.subplots(figsize=(7, 4))\nax.hist(theta_np, bins=40, color=\"#4f6db8\", alpha=0.85, density=True, label=\"Posterior samples\")\nax.axvline(posterior_mean, color=\"#d05c3b\", linestyle=\"--\", linewidth=2, label=f\"Mean = {posterior_mean:.3f}\")\nax.set(xlabel=r\"$\\theta$\", ylabel=\"Density\", title=\"Posterior for coin bias\")\nax.legend(frameon=False)\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Posterior predictive checks\n\nDraw new datasets by feeding posterior samples back through `model.sample_predictive` and compare the implied number of heads to what we observed.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "num_ppc_draws = 200\nppc_keys = jr.split(jr.PRNGKey(4), num_ppc_draws)\ntheta_subset = np.asarray(theta_samples[-num_ppc_draws:])\n\nposterior_predictive_counts = []\nfor subkey, theta_value in zip(ppc_keys, theta_subset):\n    state = {\"theta\": jnp.array(theta_value)}\n    simulated = model.sample_predictive(subkey, state)[\"y\"]\n    posterior_predictive_counts.append(np.asarray(simulated).sum())\n\nposterior_predictive_counts = np.asarray(posterior_predictive_counts)\nppc_interval = np.quantile(posterior_predictive_counts, [0.025, 0.975])\n\nprint(f\"Posterior predictive mean heads: {posterior_predictive_counts.mean():.2f}\")\nprint(f\"Posterior predictive 95% interval for heads: [{ppc_interval[0]:.1f}, {ppc_interval[1]:.1f}]\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "fig, ax = plt.subplots(figsize=(7, 4))\nbins = np.arange(-0.5, num_trials + 1.5, 1)\nax.hist(posterior_predictive_counts, bins=bins, color=\"#5aa469\", alpha=0.85, rwidth=0.9)\nax.axvline(successes, color=\"#d05c3b\", linestyle=\"--\", linewidth=2, label=f\"Observed heads = {successes}\")\nax.set(xlabel=\"Number of heads out of 20\", ylabel=\"Frequency\", title=\"Posterior predictive distribution\")\nax.set_xticks(range(0, num_trials + 1, 2))\nax.legend(frameon=False)\nplt.show()\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}