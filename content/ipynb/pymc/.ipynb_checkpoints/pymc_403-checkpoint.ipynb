{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyMC 403: Introduction to Causal Inference with PPLs\n",
    "\n",
    "Causal inference asks a deceptively simple question: \"What would have happened if things were different?\" Whether we're evaluating a job training program, testing a new medical treatment, or analyzing the impact of a policy change, we want to understand the causal effect of an intervention not just observe correlations in the data.\n",
    "\n",
    "Traditional statistical methods often struggle with causal questions because they conflate correlation with causation. When confounders variables that affect both treatment assignment and outcomes are present, naive comparisons can lead us astray. This notebook demonstrates how probabilistic programming languages (PPLs) provide a powerful framework for causal inference that makes confounding explicit, quantifies uncertainty properly, and enables us to answer counterfactual questions directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Probabilistic Programming Languages?\n",
    "\n",
    "Probabilistic Programming Languages (PPLs) like NumPyro, PyMC, and Stan offer several compelling advantages for causal inference:\n",
    "\n",
    "1. **Express causal models naturally**: We can explicitly model both the treatment assignment mechanism and the outcome process, making confounding relationships transparent in our code. This aligns perfectly with Pearl's structural causal models and the backdoor criterion.\n",
    "\n",
    "2. **Quantify uncertainty rigorously**: Bayesian inference gives us full posterior distributions, not just point estimates. We get credible intervals that properly account for all sources of uncertainty, from parameter estimation to model specification.\n",
    "\n",
    "3. **Implement the `do` operator directly**: PPLs let us implement Pearl's do-calculus naturally, allowing us to compute counterfactuals (\"what if everyone received treatment?\") by simply conditioning on interventions rather than observations.\n",
    "\n",
    "4. **Flexible modeling without sacrificing interpretability**: We can use non-linear models, hierarchical structures, and other sophisticated approaches while maintaining clear causal interpretability. The same framework works for simple linear models and complex hierarchical designs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Lalonde Dataset\n",
    "\n",
    "We'll work with the famous [Lalonde dataset](https://rugg2.github.io/Lalonde%20dataset%20-%20Causal%20Inference.html) which studies the effect of a job training program on earnings. This dataset is a classic in causal inference because it vividly demonstrates how naive comparisons can be misleading when confounders are present. The treated and control groups differ systematically in pre-treatment characteristics (age, education, prior earnings, etc.), making a simple comparison of means unreliable. By properly adjusting for these confounders, we can uncover the true causal effect of the training program.\n",
    "\n",
    "**Reference**: Robert Lalonde, \"Evaluating the Econometric Evaluations of Training Programs\", American Economic Review, Vol. 76, pp. 604-620"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpymc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransform\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconditioning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m do, observe\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m     13\u001b[39m seed: \u001b[38;5;28mint\u001b[39m = \u001b[32m42\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import arviz as az\n",
    "import graphviz as gr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import seaborn as sns\n",
    "from pymc.model.transform.conditioning import do, observe\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "seed: int = 42\n",
    "rng: np.random.Generator = np.random.default_rng(seed=seed)\n",
    "\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 6]\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"https://raw.githubusercontent.com/rugg2/rugg2.github.io/master/lalonde.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Convert the data to the right format\n",
    "data[\"re75\"] = data[\"re75\"] / 1_000\n",
    "# Add a small constant to avoid log(0) in the model\n",
    "data[\"re78\"] = data[\"re78\"] / 1_000 + 1e-6\n",
    "data = data.rename(columns={\"educ\": \"education\", \"hispan\": \"hispanic\"})\n",
    "\n",
    "# Define the covariates\n",
    "covariates_names = [\n",
    "    \"education\",\n",
    "    \"age\",\n",
    "    \"re75\",\n",
    "    \"black\",\n",
    "    \"hispanic\",\n",
    "    \"married\",\n",
    "    \"nodegree\",\n",
    "]\n",
    "\n",
    "# Extract treatment, covariates and earnings from the dataframe\n",
    "df = data[[\"treat\", *covariates_names, \"re78\"]]\n",
    "n_obs = df.shape[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal DAG\n",
    "\n",
    "Before building our models, we need to establish a clear understanding of the causal relationships in the data. We have the following structure:\n",
    "\n",
    "- **Treatment variable** (`treat`): The intervention we're studying (job training program)\n",
    "- **Outcome variable** (`re78`): What we want to measure the effect on (earnings in 1978)\n",
    "- **Covariates**: Pre-treatment variables that might confound the relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag = gr.Digraph()\n",
    "dag.node(\"treat\", color=\"#2a2eec80\", style=\"filled\")\n",
    "dag.node(\"re78\", color=\"#fa7c1780\", style=\"filled\")\n",
    "dag.node(\"covariates\")\n",
    "dag.edge(\"treat\", \"re78\")\n",
    "dag.edge(\"covariates\", \"treat\")\n",
    "dag.edge(\"covariates\", \"re78\")\n",
    "dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the concrete structure with all covariates shown:\n",
    "dag = gr.Digraph()\n",
    "dag.node(\"treat\", color=\"#2a2eec80\", style=\"filled\")\n",
    "dag.node(\"re78\", color=\"#fa7c1780\", style=\"filled\")\n",
    "dag.edge(\"treat\", \"re78\")\n",
    "for covariate in covariates_names:\n",
    "    dag.edge(covariate, \"treat\")\n",
    "    dag.edge(covariate, \"re78\")\n",
    "dag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(\n",
    "    df[[\"treat\", \"education\", \"age\", \"re75\", \"re78\"]],\n",
    "    hue=\"treat\",\n",
    "    diag_kind=\"hist\"\n",
    ")\n",
    "g.figure.suptitle(\n",
    "    \"Numerical Features Pairplot\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\",\n",
    "    y=1.03\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate what our answer would be if we just naively predicted the average earnings\n",
    "# of treated and untreated individuals, without accounting for the\n",
    "# potential confounders.\n",
    "treated_individuals = df[df[\"treat\"] == 1]\n",
    "untreated_individuals = df[df[\"treat\"] == 0]\n",
    "naive_prediction = (\n",
    "    treated_individuals[\"re78\"].mean() - untreated_individuals[\"re78\"].mean()\n",
    ")\n",
    "naive_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Confounding Problem\n",
    "\n",
    "The naive estimate simply compares average earnings between treated and untreated groups. However, if these groups differ systematically in pre-treatment characteristics (confounders), the naive estimate will be biased. For example, if the training program targeted individuals with lower prior earnings, we'd expect them to have lower earnings regardless of treatment.\n",
    "\n",
    "This is why we need to adjust for confounders—variables that affect both treatment assignment and the outcome. Our model will account for these by conditioning on covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df.groupby(\"treat\").agg(\n",
    "    count_edu=(\"education\", \"count\"),\n",
    "    count_age=(\"age\", \"count\"),\n",
    "    count_black=(\"black\", \"count\"),\n",
    "    count_hisp=(\"hispanic\", \"count\"),\n",
    "    count_marr=(\"married\", \"count\"),\n",
    "    count_nodeg=(\"nodegree\", \"count\"),\n",
    "    mean_age=(\"age\", \"mean\"),\n",
    "    mean_re75=(\"re75\", \"mean\"),\n",
    ")\n",
    "df_agg.style.background_gradient(cmap=\"viridis\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Numerical Features\n",
    "\n",
    "In general, it is recommended to scale numerical features to help MCMC sampling converge faster and to think about priors in terms of standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\"education\", \"age\", \"re75\"]\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", StandardScaler(with_mean=False), num_features),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "df_transformed = preprocessor.fit_transform(df)\n",
    "df_transformed.columns = [col.split(\"__\")[-1] for col in df_transformed.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to arrays\n",
    "covariates_obs = df_transformed[covariates_names]\n",
    "training_obs = df_transformed[\"treat\"]\n",
    "earnings_obs = df_transformed[\"re78\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Model\n",
    "\n",
    "Now we proceed to specify the model in PyMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {\n",
    "    \"covariate\": covariates_names,\n",
    "    \"obs_idx\": df.index,\n",
    "}\n",
    "\n",
    "with pm.Model(coords=coords) as earnings_model:\n",
    "    # TREATMENT MODEL\n",
    "    # --- Data Containers ---\n",
    "    covariates_data = pm.Data(\n",
    "        \"covariates_data\",\n",
    "        covariates_obs,\n",
    "        dims=(\"obs_idx\", \"covariate\")\n",
    "    )\n",
    "    \n",
    "    # --- Priors ---\n",
    "    intercept_treat = pm.Normal(\"intercept_treat\", mu=0, sigma=10)\n",
    "    beta_covariate_treat = pm.Normal(\n",
    "        \"beta_covariate_treat\",\n",
    "        mu=0,\n",
    "        sigma=1,\n",
    "        dims=(\"covariate\",)\n",
    "    )\n",
    "    \n",
    "    # --- Parametrization ---\n",
    "    logit_p_treat = intercept_treat + pm.math.dot(covariates_data, beta_covariate_treat)\n",
    "    p_treat = pm.math.sigmoid(logit_p_treat)\n",
    "    \n",
    "    # --- Likelihood ---\n",
    "    treat = pm.Bernoulli(\"treat\", p=p_treat, dims=(\"obs_idx\",))\n",
    "    \n",
    "    # EARNINGS MODEL\n",
    "    # --- Priors ---\n",
    "    intercept_earnings = pm.Normal(\"intercept_earnings\", mu=0, sigma=10)\n",
    "    beta_treat_earnings = pm.Normal(\"beta_treat_earnings\", mu=0, sigma=1)\n",
    "    beta_covariate_earnings = pm.Normal(\n",
    "        \"beta_covariate_earnings\",\n",
    "        mu=0,\n",
    "        sigma=1,\n",
    "        dims=(\"covariate\",)\n",
    "    )\n",
    "    sigma_earnings = pm.HalfNormal(\"sigma_earnings\", sigma=10.0)\n",
    "    \n",
    "    mu_earnings = pm.Deterministic(\n",
    "        \"mu_earnings\",\n",
    "        intercept_earnings\n",
    "        + beta_treat_earnings * treat\n",
    "        + pm.math.dot(covariates_data, beta_covariate_earnings),\n",
    "        dims=(\"obs_idx\",),\n",
    "    )\n",
    "    \n",
    "    # --- Likelihood ---\n",
    "    pm.Normal(\n",
    "        \"earnings\",\n",
    "        mu=mu_earnings,\n",
    "        sigma=sigma_earnings,\n",
    "        dims=(\"obs_idx\",),\n",
    "    )\n",
    "\n",
    "pm.model_to_graphviz(earnings_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Predictive Checks\n",
    "\n",
    "Before we fit the model, we can check samples from the prior distribution and compare them with the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with earnings_model:\n",
    "    idata = pm.sample_prior_predictive(samples=2_000, random_seed=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "az.plot_dist(idata[\"prior\"][\"earnings\"].to_numpy().flatten(), color=\"C0\", ax=ax)\n",
    "for i in range(50):\n",
    "    az.plot_dist(\n",
    "        idata[\"prior\"][\"earnings\"].sel(draw=i, chain=0),\n",
    "        color=\"C0\",\n",
    "        plot_kwargs={\"alpha\": 0.1},\n",
    "        ax=ax,\n",
    "    )\n",
    "az.plot_dist(earnings_obs, color=\"black\", ax=ax)\n",
    "ax.set(xlabel=\"ATE estimate\", ylabel=\"Frequency\")\n",
    "fig.suptitle(\n",
    "    \"Prior Predictive Checks (earnings) - OLS\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "az.plot_posterior(idata[\"prior\"], var_names=[\"beta_treat_earnings\"], ax=ax)\n",
    "ax.set(xlabel=\"ATE estimate\", ylabel=\"Frequency\")\n",
    "fig.suptitle(\"Prior Predictive Checks (ATE) - OLS\", fontsize=18, fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fit\n",
    "\n",
    "Now we condition the model on the observed data and sample from the posterior distribution using MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditioned_earnings_model = observe(\n",
    "    earnings_model,\n",
    "    {\"treat\": training_obs, \"earnings\": earnings_obs}\n",
    ")\n",
    "pm.model_to_graphviz(conditioned_earnings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_kwargs = {\n",
    "    \"draws\": 2_000,\n",
    "    \"tune\": 1_000,\n",
    "    \"chains\": 4,\n",
    "    \"cores\": 4,\n",
    "    \"idata_kwargs\": {\"log_likelihood\": True},\n",
    "    \"random_seed\": rng,\n",
    "}\n",
    "\n",
    "with conditioned_earnings_model:\n",
    "    idata.extend(pm.sample(**sample_kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "\n",
    "We need to assess the quality of our posterior samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = az.plot_trace(\n",
    "    data=idata,\n",
    "    var_names=[\"~mu_earnings\"],\n",
    "    compact=True,\n",
    "    backend_kwargs={\"figsize\": (12, 10), \"layout\": \"constrained\"},\n",
    ")\n",
    "plt.gcf().suptitle(\"Trace OLS\", fontsize=18, fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata, var_names=[\"~mu_earnings\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Predictive Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conditioned_earnings_model:\n",
    "    pm.sample_posterior_predictive(idata, extend_inferencedata=True, random_seed=rng)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "az.plot_ppc(idata, var_names=[\"earnings\"], num_pp_samples=200, ax=ax)\n",
    "ax.axvline(earnings_obs.mean(), color=\"C2\", label=\"observed earnings mean\")\n",
    "ax.axvline(\n",
    "    idata[\"posterior_predictive\"][\"earnings\"].mean().item(),\n",
    "    color=\"C3\",\n",
    "    label=\"posterior predictive earnings mean\",\n",
    ")\n",
    "ax.legend()\n",
    "ax.set(xlabel=\"earnings\", ylabel=\"Frequency\")\n",
    "ax.set_title(\n",
    "    \"Posterior Predictive Checks (earnings) - OLS\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATE Estimation from Coefficient\n",
    "\n",
    "In our linear model, `beta_treat_earnings` directly represents the Average Treatment Effect. Since we've adjusted for confounders, this coefficient tells us the expected change in earnings from treatment while holding all covariates constant exactly the causal interpretation we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://rugg2.github.io/Lalonde%20dataset%20-%20Causal%20Inference.html\n",
    "blog_prediction_ols = (\n",
    "    1_548.24 / 1_000\n",
    ")  # Scaled by 1000 to be consistent with data preprocessing above.\n",
    "blog_prediction_matching = 1_027.087 / 1_000\n",
    "blog_prediction_matching_ci95 = [-705.131 / 1_000, 2_759.305 / 1_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "ax.axvline(naive_prediction, color=\"C3\", label=\"naive estimate\")\n",
    "ax.axvline(blog_prediction_ols, color=\"C2\", label=\"OLS estimate\")\n",
    "ax.axvline(blog_prediction_matching, color=\"C1\", label=\"matching estimate\")\n",
    "ax.axvline(\n",
    "    blog_prediction_matching_ci95[0],\n",
    "    color=\"C1\",\n",
    "    linestyle=\"dashed\",\n",
    "    label=\"matching estimate 95% confidence\",\n",
    ")\n",
    "ax.axvline(\n",
    "    blog_prediction_matching_ci95[1],\n",
    "    color=\"C1\",\n",
    "    linestyle=\"dashed\",\n",
    ")\n",
    "az.plot_posterior(\n",
    "    idata[\"posterior\"],\n",
    "    var_names=[\"beta_treat_earnings\"],\n",
    "    kind=\"hist\",\n",
    "    bins=100,\n",
    "    ax=ax\n",
    ")\n",
    "ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.1), ncol=4)\n",
    "ax.set(xlabel=\"ATE estimate\", ylabel=\"Frequency\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATE Estimation using the `do` Operator\n",
    "\n",
    "The `do` operator represents an intervention: we force treatment to a specific value, breaking any dependence on confounders. This is the mathematical representation of \"what if everyone received treatment?\" vs \"what if no one received treatment?\"\n",
    "\n",
    "The difference between these counterfactual outcomes is the ATE. This approach is more general than coefficient interpretation—it works even with non-linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_0_earnings_model = do(\n",
    "    conditioned_earnings_model,\n",
    "    {\"treat\": np.zeros(shape=(n_obs,), dtype=np.int32)}\n",
    ")\n",
    "do_1_earnings_model = do(\n",
    "    conditioned_earnings_model,\n",
    "    {\"treat\": np.ones(shape=(n_obs,), dtype=np.int32)}\n",
    ")\n",
    "\n",
    "pm.model_to_graphviz(do_0_earnings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with do_0_earnings_model:\n",
    "    do_0_idata = pm.sample_posterior_predictive(\n",
    "        idata,\n",
    "        random_seed=rng,\n",
    "        var_names=[\"mu_earnings\"]\n",
    "    )\n",
    "\n",
    "with do_1_earnings_model:\n",
    "    do_1_idata = pm.sample_posterior_predictive(\n",
    "        idata,\n",
    "        random_seed=rng,\n",
    "        var_names=[\"mu_earnings\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_do_1 = do_1_idata[\"posterior_predictive\"][\"mu_earnings\"]\n",
    "expected_do_0 = do_0_idata[\"posterior_predictive\"][\"mu_earnings\"]\n",
    "\n",
    "# Compute the HDIs\n",
    "do_0_hdi = az.hdi(expected_do_0)[\"mu_earnings\"]\n",
    "do_1_hdi = az.hdi(expected_do_1)[\"mu_earnings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization purposes, we sort the HDIs by the mean of the HDI\n",
    "sorted_indices = np.argsort(do_0_hdi.mean(dim=\"hdi\").to_numpy())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "for i, row in enumerate(do_0_hdi[sorted_indices]):\n",
    "    do_0_label = \"do(treat = 0)\" if i == 0 else None\n",
    "    ax.hlines(\n",
    "        y=i,\n",
    "        xmin=row.sel(hdi=\"lower\"),\n",
    "        xmax=row.sel(hdi=\"higher\"),\n",
    "        linestyle=\"solid\",\n",
    "        linewidth=0.3,\n",
    "        color=\"C0\",\n",
    "    )\n",
    "    ax.plot(row.mean(), i, marker=\"o\", markersize=2, color=\"C0\", label=do_0_label)\n",
    "\n",
    "for i, row in enumerate(do_1_hdi[sorted_indices]):\n",
    "    do_1_label = \"do(treat = 1)\" if i == 0 else None\n",
    "    ax.hlines(\n",
    "        y=i,\n",
    "        xmin=row.sel(hdi=\"lower\"),\n",
    "        xmax=row.sel(hdi=\"higher\"),\n",
    "        linestyle=\"solid\",\n",
    "        linewidth=0.3,\n",
    "        color=\"C1\",\n",
    "    )\n",
    "    ax.plot(row.mean(), i, marker=\"o\", markersize=2, color=\"C1\", label=do_1_label)\n",
    "\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set(\n",
    "    xlabel=\"earnings\",\n",
    "    ylabel=\"index\",\n",
    "    title=\"Posterior Predictive Checks (earnings)\"\n",
    ")\n",
    "ax.set_title(\n",
    "    \"Posterior Predictive - OLS\\nEarnings | do(treat = 0) vs Earnings | do(treat = 1)\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ate = (expected_do_1 - expected_do_0).mean(dim=\"obs_idx\").rename(\"ate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "ax.axvline(naive_prediction, color=\"C3\", label=\"naive estimate\")\n",
    "ax.axvline(blog_prediction_ols, color=\"C2\", label=\"OLS estimate\")\n",
    "ax.axvline(blog_prediction_matching, color=\"C1\", label=\"matching estimate\")\n",
    "ax.axvline(\n",
    "    blog_prediction_matching_ci95[0],\n",
    "    color=\"C1\",\n",
    "    linestyle=\"dashed\",\n",
    "    label=\"matching estimate 95% confidence\",\n",
    ")\n",
    "ax.axvline(\n",
    "    blog_prediction_matching_ci95[1],\n",
    "    color=\"C1\",\n",
    "    linestyle=\"dashed\",\n",
    ")\n",
    "az.plot_posterior(ate, kind=\"hist\", bins=100, ax=ax)\n",
    "ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.1), ncol=4)\n",
    "ax.set(xlabel=\"ATE estimate\", ylabel=\"Frequency\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATE Estimation Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, *_ = az.plot_forest(\n",
    "    data=[idata[\"posterior\"].rename({\"beta_treat_earnings\": \"ate\"})[\"ate\"], ate],\n",
    "    model_names=[\"Coefficient\", \"Do-Operator\"],\n",
    "    var_names=[\"ate\"],\n",
    "    combined=True,\n",
    "    hdi_prob=0.94,\n",
    "    figsize=(7, 5),\n",
    ")\n",
    "ax.set_title(r\"ATE Estimation Comparison ($94\\%$ HDI)\", fontsize=18, fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Linear Model\n",
    "\n",
    "Now let's extend our analysis using a generalized linear model that ensures non-negative earnings. The overall structure remains similar, but we use a different likelihood and parametrization that better respects the domain constraints of our outcome variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model(coords=coords) as glm_earnings_model:\n",
    "    # TREATMENT MODEL\n",
    "    # --- Data Containers ---\n",
    "    covariates_data = pm.Data(\n",
    "        \"covariates_data\",\n",
    "        covariates_obs,\n",
    "        dims=(\"obs_idx\", \"covariate\")\n",
    "    )\n",
    "    \n",
    "    # --- Priors ---\n",
    "    intercept_treat = pm.Normal(\"intercept_treat\", mu=0, sigma=10)\n",
    "    beta_covariate_treat = pm.Normal(\n",
    "        \"beta_covariate_treat\",\n",
    "        mu=0,\n",
    "        sigma=1,\n",
    "        dims=(\"covariate\",)\n",
    "    )\n",
    "    \n",
    "    # --- Parametrization ---\n",
    "    logit_p_treat = intercept_treat + pm.math.dot(covariates_data, beta_covariate_treat)\n",
    "    p_treat = pm.math.sigmoid(logit_p_treat)\n",
    "    \n",
    "    # --- Likelihood ---\n",
    "    treat = pm.Bernoulli(\"treat\", p=p_treat, dims=(\"obs_idx\",))\n",
    "    \n",
    "    # EARNINGS MODEL\n",
    "    # --- Priors ---\n",
    "    intercept_earnings = pm.Normal(\"intercept_earnings\", mu=0, sigma=10)\n",
    "    beta_treat_earnings = pm.Normal(\"beta_treat_earnings\", mu=0, sigma=1)\n",
    "    beta_covariate_earnings = pm.Normal(\n",
    "        \"beta_covariate_earnings\",\n",
    "        mu=0,\n",
    "        sigma=1,\n",
    "        dims=(\"covariate\",)\n",
    "    )\n",
    "    sigma_earnings = pm.HalfNormal(\"sigma_earnings\", sigma=10)\n",
    "    \n",
    "    # --- Parametrization ---\n",
    "    raw_mu_earnings = (\n",
    "        intercept_earnings\n",
    "        + beta_treat_earnings * treat\n",
    "        + pm.math.dot(covariates_data, beta_covariate_earnings)\n",
    "    )\n",
    "    mu_earnings = pm.Deterministic(\n",
    "        \"mu_earnings\",\n",
    "        pt.softplus(raw_mu_earnings),\n",
    "        dims=(\"obs_idx\",)\n",
    "    )\n",
    "    \n",
    "    # --- Likelihood ---\n",
    "    pm.Gamma(\n",
    "        \"earnings\",\n",
    "        mu=mu_earnings,\n",
    "        sigma=sigma_earnings,\n",
    "        dims=(\"obs_idx\",),\n",
    "    )\n",
    "\n",
    "pm.model_to_graphviz(glm_earnings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with glm_earnings_model:\n",
    "    glm_idata = pm.sample_prior_predictive(samples=2_000, random_seed=rng)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "az.plot_dist(glm_idata[\"prior\"][\"earnings\"].to_numpy().flatten(), color=\"C0\", ax=ax)\n",
    "az.plot_dist(earnings_obs, color=\"black\", ax=ax)\n",
    "ax.set(xlabel=\"ATE estimate\", ylabel=\"Frequency\", xlim=(-10, 100))\n",
    "fig.suptitle(\n",
    "    \"Prior Predictive Checks (earnings) - GLM\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_conditioned_earnings_model = observe(\n",
    "    glm_earnings_model,\n",
    "    {\"treat\": training_obs, \"earnings\": earnings_obs}\n",
    ")\n",
    "\n",
    "with glm_conditioned_earnings_model:\n",
    "    glm_idata = pm.sample(**sample_kwargs)\n",
    "    pm.sample_posterior_predictive(\n",
    "        glm_idata,\n",
    "        extend_inferencedata=True,\n",
    "        random_seed=rng\n",
    "    )\n",
    "\n",
    "axes = az.plot_trace(\n",
    "    data=glm_idata,\n",
    "    var_names=[\"~mu_earnings\"],\n",
    "    compact=True,\n",
    "    backend_kwargs={\"figsize\": (12, 10), \"layout\": \"constrained\"},\n",
    ")\n",
    "plt.gcf().suptitle(\"Trace GLM\", fontsize=18, fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "az.plot_ppc(glm_idata, var_names=[\"earnings\"], num_pp_samples=200, ax=ax)\n",
    "ax.axvline(earnings_obs.mean(), color=\"C2\", label=\"observed earnings mean\")\n",
    "ax.axvline(\n",
    "    glm_idata[\"posterior_predictive\"][\"earnings\"].mean().item(),\n",
    "    color=\"C3\",\n",
    "    label=\"posterior predictive earnings mean\",\n",
    ")\n",
    "ax.legend()\n",
    "ax.set(xlabel=\"earnings\", ylabel=\"Frequency\", xlim=(None, 50))\n",
    "ax.set_title(\n",
    "    \"Posterior Predictive Checks (earnings) - GLM\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_do_0_earnings_model = do(\n",
    "    glm_conditioned_earnings_model,\n",
    "    {\"treat\": np.zeros(shape=(n_obs,), dtype=np.int32)}\n",
    ")\n",
    "glm_do_1_earnings_model = do(\n",
    "    glm_conditioned_earnings_model,\n",
    "    {\"treat\": np.ones(shape=(n_obs,), dtype=np.int32)}\n",
    ")\n",
    "\n",
    "with glm_do_0_earnings_model:\n",
    "    glm_do_0_idata = pm.sample_posterior_predictive(\n",
    "        glm_idata,\n",
    "        random_seed=rng,\n",
    "        var_names=[\"mu_earnings\"]\n",
    "    )\n",
    "\n",
    "with glm_do_1_earnings_model:\n",
    "    glm_do_1_idata = pm.sample_posterior_predictive(\n",
    "        glm_idata,\n",
    "        random_seed=rng,\n",
    "        var_names=[\"mu_earnings\"]\n",
    "    )\n",
    "\n",
    "glm_expected_do_1 = glm_do_1_idata[\"posterior_predictive\"][\"mu_earnings\"]\n",
    "glm_expected_do_0 = glm_do_0_idata[\"posterior_predictive\"][\"mu_earnings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_ate = (glm_expected_do_1 - glm_expected_do_0).mean(dim=\"obs_idx\").rename(\"ate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, *_ = az.plot_forest(\n",
    "    data=[\n",
    "        idata[\"posterior\"].rename({\"beta_treat_earnings\": \"ate\"})[\"ate\"],\n",
    "        ate,\n",
    "        glm_ate,\n",
    "    ],\n",
    "    model_names=[\"Coefficient\", \"Do-Operator\", \"GLM\"],\n",
    "    var_names=[\"ate\"],\n",
    "    combined=True,\n",
    "    hdi_prob=0.94,\n",
    "    figsize=(7, 5),\n",
    ")\n",
    "ax.set_title(r\"ATE Estimation Comparison ($94\\%$ HDI)\", fontsize=18, fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = az.compare(\n",
    "    compare_dict={\n",
    "        \"OLS\": idata,\n",
    "        \"GLM\": glm_idata,\n",
    "    },\n",
    "    var_name=\"earnings\",\n",
    "    ic=\"loo\",\n",
    ")\n",
    "az.plot_compare(compare_df, figsize=(7, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've explored how probabilistic programming languages, specifically PyMC, provide a powerful and intuitive framework for causal inference. Through our analysis of the Lalonde dataset, we've demonstrated several key principles:\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Confounding matters**: The naive comparison of treated and untreated groups gave a misleading estimate of the treatment effect. By explicitly modeling confounders—variables that affect both treatment assignment and outcomes—we obtained more reliable causal estimates.\n",
    "\n",
    "2. **Bayesian inference provides full uncertainty quantification**: Rather than just point estimates and confidence intervals, we obtained full posterior distributions for the Average Treatment Effect (ATE), giving us a richer understanding of uncertainty that accounts for all sources of variation.\n",
    "\n",
    "3. **The `do` operator enables counterfactual reasoning**: By implementing Pearl's do-calculus directly in PyMC, we could answer \"what if\" questions—computing counterfactual outcomes under different treatment scenarios. This approach is more general than coefficient interpretation and works seamlessly with non-linear models.\n",
    "\n",
    "4. **Model validation is essential**: Through prior predictive checks, convergence diagnostics, and posterior predictive checks, we ensured our models were well-specified and our inferences were reliable. The comparison between OLS and GLM models highlighted the importance of choosing appropriate likelihood functions that respect domain constraints."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
